@misc{2020,
  title = {{{MIT}} Tech Uses Muscle Signals to Control a Drone},
  year = {2020},
  month = may,
  journal = {New Atlas},
  urldate = {2024-01-04},
  abstract = {If you've ever piloted a drone, you'll know that utilizing a joystick-style controller takes some getting used to. MIT scientists have developed what they claim is a more intuitive control system, that reads the operator's muscle signals.},
  chapter = {Drones},
  howpublished = {https://newatlas.com/drones/muscle-signals-drone-control/},
  langid = {american}
}

@misc{2022,
  title = {Swarm {{Robotics}}: {{A New Frontier}} -- {{Hadron}}},
  shorttitle = {Swarm {{Robotics}}},
  year = {2022},
  month = feb,
  urldate = {2024-03-23},
  langid = {american},
  file = {/home/test/Zotero/storage/XNKYKL2M/swarm-robotics-a-new-frontier.html}
}

@inproceedings{abdi2023,
  title = {Safe {{Operations}} of an {{Aerial Swarm}} via a {{Cobot Human Swarm Interface}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Abdi, Sydrak S. and Paley, Derek A.},
  year = {2023},
  month = may,
  pages = {1701--1707},
  doi = {10.1109/ICRA48891.2023.10161343},
  urldate = {2024-01-09},
  abstract = {Command and control of an aerial swarm is a complex task. This task increases in difficulty when the flight volume is restricted and the swarm and operator inhabit the same workspace. This work presents a novel method for interacting with and controlling a swarm of quadrotors in a confined space. EMG-based gesture control is used to control the position, orientation, and density of the swarm. Inter-agent as well as agent-operator collisions are prevented through a velocity controller based on a distance-based potential function. State feedback is relayed to the operator via a vibrotactile haptic vest. This cobot human swarm interface prioritizes operator safety while reducing the cognitive load during control of a cobot swarm. This work demonstrates that an operator can safely and intuitively control a swarm of aerial robots in the same workspace.},
  file = {/home/test/Zotero/storage/W9SSJNSZ/10161343.html}
}

@inproceedings{ali2020,
  title = {{{EMG Based Control}} of a {{Quadcopter}}},
  booktitle = {2020 3rd {{International Conference}} on {{Mechanical}}, {{Electronics}}, {{Computer}}, and {{Industrial Technology}} ({{MECnIT}})},
  author = {Ali, Maham and Riaz, Areeba and Usmani, Waleef Ullah and Naseer, Noman},
  year = {2020},
  month = jun,
  pages = {250--254},
  doi = {10.1109/MECnIT48290.2020.9166603},
  urldate = {2024-01-04},
  abstract = {In this paper, we present a work on control of quadcopter using electromyography (EMG) signals acquired from subject's muscles. A simple yet effective interface is maneuvered that can permit even amateur users to control a quadcopter. EMG signals were acquired using eight electrodes of MyoArm band while the subjects performed four different hand gestures to control the quadcopter in four different directions. Moreover, those signals were filtered to remove noises-the noise-free signal was then used to acquire features that could be used for classification of different hand gestures. After acquiring suitable features, linear discriminant analysis was used to classify and generate control commands to control the quadcopter. Results demonstrate the feasibility in using EMG to control a quadcopter effectively with little training.}
}

@article{anzai2023,
  title = {Effects of Continuous Drone Herding on Behavioral Response and Spatial Distribution of Grazing Cattle},
  author = {Anzai, Hiroki and Kumaishi, Mahiro},
  year = {2023},
  month = nov,
  journal = {Applied Animal Behaviour Science},
  volume = {268},
  pages = {106089},
  issn = {0168-1591},
  doi = {10.1016/j.applanim.2023.106089},
  urldate = {2024-01-09},
  abstract = {Robotic herding is expected to become a new technology for the management of grazing animals. We investigated the behavioral responses of cows to drone herding on consecutive days and the potential of this technology to manipulate grazing distribution in a pasture. A herd of {$\sim$}30 cows was stocked in a 1.1-ha pasture for 5 consecutive days each month from May to October 2022. The cows were herded using a drone for 10 days during the grazing period in August (days 1--5) and September (days 6--10). The pasture was divided into nine plots, with two and three plots assigned as the `herding area' in August and September, respectively. When the cows were grazing in the herding area, the operator maneuvered the drone to move the animals out of the area. The drone first approached at an altitude of 10\,m; if the cows did not move away, the altitude was gradually lowered to 3\,m. The behavioral responses to the drone, success or failure of herding (whether the cows left the area or not), and drone altitude were classified based on videos recorded during herding. The behavior and location of the cows in the pasture were observed during this period. The utilization rates of the plots (percentage of grazing time) were calculated to evaluate the effects of herding and the number of herding days. The cows responded in 59\% and 46\% of the cases on days 1 and 2, respectively. Startle behavior was recorded in 23\% of the responses on day 1. Herding was successful in 51--75\% of the cases on days 1--3. However, these percentages decreased thereafter. The utilization rate of the herding area on day 1 was approximately half that on days without herding. It increased from day 2, and almost no effect on grazing distribution was observed on or after day 3. These findings suggest that the cows exhibited little fear of drones after 1-day herding, and responses to the drones decreased as the animals subsequently became habituated to frequently repeated stimuli. Even after a 24-day interval, responsiveness to drone herding barely recovered and then declined. Therefore, drone herding was hardly effective in manipulating grazing distribution. Further investigation of stimulation that persistently elicits desirable responses is needed for future applications in technologies for the autonomous control of animal movement.},
  keywords = {Habituation,Pasture use,Precision livestock farming,Robotic herding,Unmanned aerial vehicle},
  file = {/home/test/Zotero/storage/UULSAFL3/S0168159123002617.html}
}

@article{barnesAVIATRAerialVehicle2012,
  title = {{{AVIATR}}---{{Aerial Vehicle}} for {{In-situ}} and {{Airborne Titan Reconnaissance}}: {{A Titan}} Airplane Mission Concept},
  shorttitle = {{{AVIATR}}---{{Aerial Vehicle}} for {{In-situ}} and {{Airborne Titan Reconnaissance}}},
  author = {Barnes, Jason W. and Lemke, Lawrence and Foch, Rick and McKay, Christopher P. and Beyer, Ross A. and Radebaugh, Jani and Atkinson, David H. and Lorenz, Ralph D. and Le Mou{\'e}lic, St{\'e}phane and Rodriguez, Sebastien and Gundlach, Jay and Giannini, Francesco and Bain, Sean and Flasar, F. Michael and Hurford, Terry and Anderson, Carrie M. and Merrison, Jon and {\'A}d{\'a}mkovics, M{\'a}t{\'e} and Kattenhorn, Simon A. and Mitchell, Jonathan and Burr, Devon M. and Colaprete, Anthony and Schaller, Emily and Friedson, A. James and Edgett, Kenneth S. and Coradini, Angioletta and Adriani, Alberto and Sayanagi, Kunio M. and Malaska, Michael J. and Morabito, David and Reh, Kim},
  year = {2012},
  month = mar,
  journal = {Exp Astron},
  volume = {33},
  number = {1},
  pages = {55--127},
  issn = {0922-6435, 1572-9508},
  doi = {10.1007/s10686-011-9275-9},
  urldate = {2024-01-04},
  langid = {english},
  keywords = {mission concept},
  file = {/home/test/Zotero/storage/4KYRJVA3/Barnes et al. - 2012 - AVIATRâ€”Aerial Vehicle for In-situ and Airborne Tit.pdf}
}

@article{barton2006,
  title = {{{PLANTS DEMO}} - {{Enabling}} Mixed Societies of Communicating Plants and Artefacts},
  author = {Barton, John and O'Flynn, Brendan and Aherne, Kevin and Morrissey, Anthony and Cassells, Alan and Drossos, Nikos and Goumopoulos, Christos and Tooke, Fiona and {Whitbread-Abrutat}, Peter},
  year = {2006},
  urldate = {2024-01-07},
  abstract = {Several applications, such as precision farming, military field monitoring and seismic activity monitoring require reliable and extended lifetime deployments of potentially a very large number of wireless sensor and actuator nodes. As hardware becomes cheaper and smaller, more of these applications are likely to appear, particularly as these miniaturised nodes offer the opportunity for the electronics to be embedded unobtrusively into everyday objects. This paper will present results from an EU funded project, PLANTS. PLANTS is a research project devising a novel technology that will allow plants to control their own environments. Using this technology, plant signals are detected, analysed and an appropriate response activated. The PLANTS system automatically responds to a plant's needs.},
  langid = {english},
  file = {/home/test/Zotero/storage/8PSL2MPS/Barton et al. - 2006 - PLANTS DEMO - Enabling mixed societies of communic.pdf}
}

@article{calderon-arce2022,
  title = {Swarm {{Robotics}}: {{Simulators}}, {{Platforms}} and {{Applications Review}}},
  shorttitle = {Swarm {{Robotics}}},
  author = {{Calder{\'o}n-Arce}, Cindy and {Brenes-Torres}, Juan Carlos and {Solis-Ortega}, Rebeca},
  year = {2022},
  month = jun,
  journal = {Computation},
  volume = {10},
  number = {6},
  pages = {80},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-3197},
  doi = {10.3390/computation10060080},
  urldate = {2024-01-13},
  abstract = {This paper presents an updated and broad review of swarm robotics research papers regarding software, hardware, simulators and applications. The evolution from its concept to its real-life implementation is presented. Swarm robotics analysis is focused on four aspects: conceptualization, simulators, real-life robotics for swarm use, and applications. For simulators and robots, a detailed comparison between existing resources is made. A summary of the most used swarm robotics applications and behaviors is included.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {review,robots,simulators,swarm robotics},
  file = {/home/test/Zotero/storage/EA6QFUZP/CalderÃ³n-Arce et al. - 2022 - Swarm Robotics Simulators, Platforms and Applicat.pdf}
}

@article{campionUAVSwarmCommunication2019,
  title = {{{UAV}} Swarm Communication and Control Architectures: A Review},
  shorttitle = {{{UAV}} Swarm Communication and Control Architectures},
  author = {Campion, Mitch and Ranganathan, Prakash and Faruque, Saleh},
  year = {2019},
  month = jun,
  journal = {J. Unmanned Veh. Sys.},
  volume = {7},
  number = {2},
  pages = {93--106},
  publisher = {NRC Research Press},
  issn = {2291-3467},
  doi = {10.1139/juvs-2018-0009},
  urldate = {2024-01-04},
  abstract = {Unmanned aerial vehicles (UAVs) have significantly disrupted the aviation industry. As technology and policy continue to develop, this disruption is only going to increase in magnitude. A specific technology poised to escalate this disruption is UAV swarm. UAV swarm has the potential to distribute tasks and coordinate operation of many UAVs with little to no operator intervention. This paper surveys literature regarding UAV swarm and proposes a swarm architecture that will allow for higher levels of swarm autonomy and reliability by utilizing cellular mobile wireless communication infrastructure. This paper chronicles initial testbed development to meet this proposed architecture. Focused development of UAV swarms with UAV-to-UAV communication autonomous coordination ability is central to advancing the utility of UAV swarms. The use of cellular mobile framework alleviates many limiting factors that hinder the utility of UAVs including range of communication, networking challenges, and size-weight-and-power considerations. In addition, cellular networks leverage a robust and reliable infrastructure for machine to machine communication proposed by 5G systems.},
  file = {/home/test/Zotero/storage/EZGCI2H4/Campion et al. - 2019 - UAV swarm communication and control architectures.pdf}
}

@article{castelloferrer2017,
  title = {A Wearable General-Purpose Solution for {{Human-Swarm Interaction}}},
  author = {Castell{\'o} Ferrer, Eduardo},
  year = {2017},
  month = may,
  urldate = {2024-01-04},
  abstract = {Swarms of robots will revolutionize many industrial applications, from targeted material delivery to precision farming. Controlling the motion and behavior of these swarms presents unique challenges for human operators, who cannot yet effectively convey their high-level intentions to a group of robots in application. This work proposes a new human-swarm interface based on novel wearable gesture-control and haptic-feedback devices. This work seeks to combine a wearable gesture recognition device that can detect high-level intentions, a portable device that can detect Cartesian information and finger movements, and a wearable advanced haptic device that can provide real-time feedback. This project is the first to envisage a wearable Human-Swarm Interaction (HSI) interface that separates the input and feedback components of the classical control loop (input, output, feedback), as well as being the first of its kind suitable for both indoor and outdoor environments.},
  copyright = {Attribution-NonCommercial-ShareAlike 4.0},
  langid = {english},
  annotation = {Accepted: 2017-05-11T18:57:49Z}
}

@article{ceolini2020,
  title = {Hand-{{Gesture Recognition Based}} on {{EMG}} and {{Event-Based Camera Sensor Fusion}}: {{A Benchmark}} in {{Neuromorphic Computing}}},
  shorttitle = {Hand-{{Gesture Recognition Based}} on {{EMG}} and {{Event-Based Camera Sensor Fusion}}},
  author = {Ceolini, Enea and Frenkel, Charlotte and Shrestha, Sumit Bam and Taverni, Gemma and Khacef, Lyes and Payvand, Melika and Donati, Elisa},
  year = {2020},
  journal = {Frontiers in Neuroscience},
  volume = {14},
  issn = {1662-453X},
  urldate = {2024-01-09},
  abstract = {Hand gestures are a form of non-verbal communication used by individuals in conjunction with speech to communicate. Nowadays, with the increasing use of technology, hand-gesture recognition is considered to be an important aspect of Human-Machine Interaction (HMI), allowing the machine to capture and interpret the user's intent and to respond accordingly. The ability to discriminate between human gestures can help in several applications, such as assisted living, healthcare, neuro-rehabilitation, and sports. Recently, multi-sensor data fusion mechanisms have been investigated to improve discrimination accuracy. In this paper, we present a sensor fusion framework that integrates complementary systems: the electromyography (EMG) signal from muscles and visual information. This multi-sensor approach, while improving accuracy and robustness, introduces the disadvantage of high computational cost, which grows exponentially with the number of sensors and the number of measurements. Furthermore, this huge amount of data to process can affect the classification latency which can be crucial in real-case scenarios, such as prosthetic control. Neuromorphic technologies can be deployed to overcome these limitations since they allow real-time processing in parallel at low power consumption. In this paper, we present a fully neuromorphic sensor fusion approach for hand-gesture recognition comprised of an event-based vision sensor and three different neuromorphic processors. In particular, we used the event-based camera, called DVS, and two neuromorphic platforms, Loihi and ODIN + MorphIC. The EMG signals were recorded using traditional electrodes and then converted into spikes to be fed into the chips. We collected a dataset of five gestures from sign language where visual and electromyography signals are synchronized. We compared a fully neuromorphic approach to a baseline implemented using traditional machine learning approaches on a portable GPU system. According to the chip's constraints, we designed specific spiking neural networks (SNNs) for sensor fusion that showed classification accuracy comparable to the software baseline. These neuromorphic alternatives have increased inference time, between 20 and 40\%, with respect to the GPU system but have a significantly smaller energy-delay product (EDP) which makes them between 30{\texttimes} and 600{\texttimes} more efficient. The proposed work represents a new benchmark that moves neuromorphic computing toward a real-world scenario.},
  file = {/home/test/Zotero/storage/CZ4UBBNW/Ceolini et al. - 2020 - Hand-Gesture Recognition Based on EMG and Event-Ba.pdf}
}

@article{cote-allard2019,
  title = {A {{Low-Cost}}, {{Wireless}}, 3-{{D-Printed Custom Armband}} for {{sEMG Hand Gesture Recognition}}},
  author = {{C{\^o}t{\'e}-Allard}, Ulysse and {Gagnon-Turcotte}, Gabriel and Laviolette, Fran{\c c}ois and Gosselin, Benoit},
  year = {2019},
  month = jan,
  journal = {Sensors},
  volume = {19},
  number = {12},
  pages = {2811},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s19122811},
  urldate = {2024-01-09},
  abstract = {Wearable technology can be employed to elevate the abilities of humans to perform demanding and complex tasks more efficiently. Armbands capable of surface electromyography (sEMG) are attractive and noninvasive devices from which human intent can be derived by leveraging machine learning. However, the sEMG acquisition systems currently available tend to be prohibitively costly for personal use or sacrifice wearability or signal quality to be more affordable. This work introduces the 3DC Armband designed by the Biomedical Microsystems Laboratory in Laval University; a wireless, 10-channel, 1000 sps, dry-electrode, low-cost ({$\sim$}150 USD) myoelectric armband that also includes a 9-axis inertial measurement unit. The proposed system is compared with the Myo Armband by Thalmic Labs, one of the most popular sEMG acquisition systems. The comparison is made by employing a new offline dataset featuring 22 able-bodied participants performing eleven hand/wrist gestures while wearing the two armbands simultaneously. The 3DC Armband systematically and significantly (    p {$<$} 0.05    ) outperforms the Myo Armband, with three different classifiers employing three different input modalities when using ten seconds or more of training data per gesture. This new dataset, alongside the source code, Altium project and 3-D models are made readily available for download within a Github repository.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {acquisition system,gesture recognition,sEMG,surface electromyogram,wearable sensors},
  file = {/home/test/Zotero/storage/7KBXCK3T/CÃ´tÃ©-Allard et al. - 2019 - A Low-Cost, Wireless, 3-D-Printed Custom Armband f.pdf}
}

@article{couceiro2014,
  title = {Benchmark of Swarm Robotics Distributed Techniques in a Search Task},
  author = {Couceiro, Micael S. and Vargas, Patricia A. and Rocha, Rui P. and Ferreira, Nuno M. F.},
  year = {2014},
  month = feb,
  journal = {Robotics and Autonomous Systems},
  volume = {62},
  number = {2},
  pages = {200--213},
  issn = {0921-8890},
  doi = {10.1016/j.robot.2013.10.004},
  urldate = {2024-01-09},
  abstract = {This paper presents a survey on multi-robot search inspired by swarm intelligence by further classifying and discussing the theoretical advantages and disadvantages of the existing studies. Subsequently, the most attractive techniques are evaluated and compared by highlighting their most relevant features. This is motivated by the gradual growth of swarm robotics solutions in situations where conventional search cannot find a satisfactory solution. For instance, exhaustive multi-robot search techniques, such as sweeping the environment, allow for a better avoidance of local solutions but require too much time to find the optimal one. Moreover, such techniques tend to fail in finding targets within dynamic and unstructured environments. This paper presents experiments conducted to benchmark five state-of-the-art algorithms for cooperative exploration tasks. The simulated experimental results show the superiority of the previously presented Robotic Darwinian Particle Swarm Optimization (RDPSO), evidencing that sociobiological inspiration is useful to meet the challenges of robotic applications that can be described as optimization problems (e.g.,~search and rescue). Moreover, the RDPSO is further compared with the best performing algorithms within a population of 14 e-pucks. It is observed that the RDPSO algorithm converges to the optimal solution faster and more accurately than the other approaches without significantly increasing the computational demand, memory and communication complexity.},
  keywords = {Benchmark,Performance analysis,Search tasks,Swarm robotics},
  file = {/home/test/Zotero/storage/E3STYUT9/Couceiro et al. - 2014 - Benchmark of swarm robotics distributed techniques.pdf;/home/test/Zotero/storage/5TCGWSJY/S092188901300208X.html}
}

@article{dadashpour2022,
  title = {The Role of Industry 4.0 Technologies in Overcoming Pandemic Challenges for the Manufacturing Sector},
  author = {Dadash Pour, Parham and Nazzal, Mohammad A and Darras, Basil M},
  year = {2022},
  month = jun,
  journal = {Concurr Eng Res Appl},
  volume = {30},
  number = {2},
  pages = {190--205},
  issn = {1063-293X},
  doi = {10.1177/1063293X221082681},
  urldate = {2024-01-08},
  abstract = {Industry 4.0 aims to revolutionize the manufacturing sector to achieve sustainable and efficient production. The novel coronavirus pandemic has brought many challenges in different industries globally. Shortage in supply of raw material, changes in product demand, and factories closures due to general lockdown are all examples of such challenges. The adaption of Industry 4.0 technologies can address these challenges and prevent their recurrence in case of another pandemic outbreak in future. A prominent advantage of Industry 4.0 technologies is their capability of building resilient and flexible systems that are responsive to exceptional circumstances such as unpredictable market demand, supply chain interruptions, and manpower shortage which can be crucial at times of pandemics. This work focuses on discussing how different Industry 4.0 technologies such as Cyber Physical Systems, Additive Manufacturing, and Internet of Things can help the manufacturing sector overcome pandemics challenges. The role of Industry 4.0 technologies in raw material provenance identification and counterfeit prevention, collaboration and business continuity, agility and decentralization of manufacturing, crisis simulation, elimination of single point of failure risk, and other factors is discussed. Moreover, a self-assessment readiness model has been developed to help manufacturing firms determine their readiness level for implementing different Industry 4.0 technologies.},
  pmcid = {PMC9096009},
  pmid = {null},
  file = {/home/test/Zotero/storage/NZHEJHT9/Dadash Pour et al. - 2022 - The role of industry 4.0 technologies in overcomin.pdf}
}

@article{deng2022,
  title = {Shepherding {{Control}} for {{Separating}} a {{Single Agent}} from a {{Swarm}}*},
  author = {Deng, Yaosheng and Ogura, Masaki and Li, Aiyi and Wakamiya, Naoki},
  year = {2022},
  month = jan,
  journal = {IFAC-PapersOnLine},
  series = {1st {{IFAC Workshop}} on {{Control}} of {{Complex Systems COSY}} 2022},
  volume = {55},
  number = {40},
  pages = {217--222},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2023.01.075},
  urldate = {2024-01-09},
  abstract = {In this paper, we consider the swarm-control problem of spatially separating a specified target agent within the swarm from all the other agents, while maintaining the connectivity among the other agents. We specifically aim to achieve the separation by designing the movement algorithm of an external agent, called a shepherd, which exerts repulsive forces on the agents in the swarm. This problem has potential applications in the context of the manipulation of the swarm of micro- and nano-particles. We first formulate the separation problem, where the swarm agents (called sheep) are modeled by the Boid model. We then analytically study the special case of two-sheep swarms. By leveraging the analysis, we then propose a potential function-based movement algorithm of the shepherd to achieve separation while maintaining the connectivity within the remaining swarm. We demonstrate the effectiveness of the proposed algorithm with numerical simulations.},
  keywords = {Separation,Shepherding,Swarm control},
  file = {/home/test/Zotero/storage/4KZTXKDQ/Deng et al. - 2022 - Shepherding Control for Separating a Single Agent .pdf;/home/test/Zotero/storage/45N4LAY5/S2405896323000800.html}
}

@inproceedings{doshi2021,
  title = {Designing a {{Drone Controller}} Using {{Electromyography Signals}}},
  booktitle = {2021 {{International Conference}} on {{Communication}} Information and {{Computing Technology}} ({{ICCICT}})},
  author = {Doshi, Yash and Nath, Divyanshi},
  year = {2021},
  month = jun,
  pages = {1--6},
  doi = {10.1109/ICCICT50803.2021.9510045},
  urldate = {2024-01-04},
  abstract = {The aim of this project is to introduce new-fangled way to control Unmanned Aerial Vehicle (UAV) using electromyography (EMG) signal. Electromyography signals are biopotential signals that are generated when any muscular action takes place in a person's body. The idea is to provide a novel method of controlling drones, and other remote-controlled objects by recognizing hand gestures using EMG Signals. This paper presents a controller designed that can be easily fitted to a band on the user's arm. It is composed by inertial (gyroscope, accelerometer) and electromyographic sensors, that will measure the muscle movements and construe them in references for the drone. Gesture recognition is achieved using an Artificial Neural Network to fully exploit the capabilities of both, the user and UAV - Unmanned Aerial Vehicle. UAV chosen to test with the controller is a quadcopter. The comparative results show the compactness and easy-to-handle interface that allows even inexperienced users, to intuitively have control over remote-controlled objects as compared to a standard remote controller.}
}

@misc{Dragonfly,
  title = {Dragonfly},
  urldate = {2024-01-01},
  howpublished = {https://dragonfly.jhuapl.edu/News-and-Resources/},
  file = {/home/test/Zotero/storage/TLS9BTA8/News-and-Resources.html}
}

@article{dudhanikarGestureControlledSwarm2023,
  title = {Gesture {{Controlled Swarm}} of {{Mini Aerial}} Vehicles},
  author = {Dudhanikar, Mr Vijaykumar},
  year = {2023},
  volume = {11},
  number = {5},
  abstract = {Image processing technique is one of the crucial technologies in the modern world problem solving systems. Various application of image processing has been introduced and also are being utilized in the present era. The classification, analysis and approaches of this technique are available in abundant, but the difference between such techniques are still known only to few. It is essential that proper distinctions between such techniques should be interpreted and they should be analyzed. The main aim in our project is to control mini aerial vehicles or micro drones by recognizing and classifying hand gestures to correct directions or instructions for the movement of drones with maximum accuracy possible. This will be done with use of certain hardware components and image processing scripts with a dataset of different hand gestures for different movements or directions.},
  langid = {english},
  file = {/home/test/Zotero/storage/HVJZ433E/Dudhanikar - 2023 - Gesture Controlled Swarm of Mini Aerial vehicles.pdf}
}

@misc{duerr2020,
  title = {Eurythmic {{Dancing}} with {{Plants}} -- {{Measuring Plant Response}} to {{Human Body Movement}} in an {{Anthroposophic Environment}}},
  author = {Duerr, Sebastian and {van Delden}, Josephine and Oezkaya, Buenyamin and Gloor, Peter A.},
  year = {2020},
  month = dec,
  number = {arXiv:2012.12978},
  eprint = {2012.12978},
  primaryclass = {cs, eess, q-bio},
  publisher = {arXiv},
  urldate = {2024-01-07},
  abstract = {This paper describes three experiments measuring interaction of humans with garden plants. In particular, body movement of a human conducting eurythmic dances near the plants (beetroots, tomatoes, lettuce) is correlated with the action potential measured by a plant SpikerBox, a device measuring the electrical activity of plants, and the leaf movement of the plant, tracked with a camera. The first experiment shows that our measurement system captures external stimuli identically for different plants, validating the measurement system. The second experiment illustrates that the plants' response is correlated to the movements of the dancer. The third experiment indicates that plants that have been exposed for multiple weeks to eurythmic dancing might respond differently to plants which are exposed for the first time to eurythmic dancing.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Quantitative Biology - Other Quantitative Biology},
  file = {/home/test/Zotero/storage/9ZHAHITR/Duerr et al. - 2020 - Eurythmic Dancing with Plants -- Measuring Plant R.pdf;/home/test/Zotero/storage/8E3RQY25/2012.html}
}

@inproceedings{easterly2004,
  title = {Bio-{{Fi}}: Inverse Biotelemetry Projects},
  shorttitle = {Bio-{{Fi}}},
  booktitle = {Proceedings of the 12th Annual {{ACM}} International Conference on {{Multimedia}}},
  author = {Easterly, Douglas},
  year = {2004},
  month = oct,
  series = {{{MULTIMEDIA}} '04},
  pages = {182--183},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1027527.1027568},
  urldate = {2024-01-07},
  abstract = {Bio-Fi is a collection of art projects undertaken by S.W.A.M.P. (Studies of Work Atmospheres and Mass Production), collaborative art projects by Douglas Easterly and Matt Kenyon. S.W.A.M.P. projects attempt to find creative expression within elements of culture that are inherently counter-creative. The Bio-Fi series utilizes physical computing technology to access patterns and relationships surrounding a corporation, that couldn't be seen using any other medium. The field of 'biotelemetry' researches ways of gathering vital physiological data from living organisms through transponders (worn or implanted), which relay information to remote hardware [1]. With all biotelemetric applications, it is integral that the transponder-bearing subject is a synecdoche for its larger social group. In this respect, Bio-Fi projects are a sort of 'inverse-biotelemetry'. Test subjects are not released into a natural environment, but trapped within a synthetic environment whose conditions are tempered by various systems of information: Wi-Fi signals are like water, information mined from the internet is food, and electronic pulses become sunlight.},
  isbn = {978-1-58113-893-1},
  keywords = {art,economics,inverse biotelemetry,physical computing}
}

@article{ekelhof2020,
  title = {Swarm {{Robotics}}: {{Technical}} and {{Operational Overview}} of the {{Next Generation}} of {{Autonomous Systems}}},
  shorttitle = {Swarm {{Robotics}}},
  author = {Ekelhof, Merel and Paoli, Giacomo Persi},
  year = {2020},
  month = aug,
  urldate = {2024-01-09},
  abstract = {As the international community continues discussions on lethal autonomous weapons systems (LAWS) in 2020 and 2021 and will focus on the further development and operationalization of the guiding principles, the role of human decision-making will undoubtedly remain one of the core issues. By drawing on near-term technologies, such as swarms, and related command and control models in deliberations},
  langid = {british},
  file = {/home/test/Zotero/storage/533TW5F8/Ekelhof and Paoli - 2020 - Swarm Robotics Technical and Operational Overview.pdf}
}

@misc{electronicstutorial2019,
  title = {Butterworth {{Filter Design}}},
  author = {{Electronics tutorial}},
  year = {2019},
  month = nov
}

@inproceedings{fukui2009,
  title = {Development of Teaching Pendant Optimized for Robot Application},
  booktitle = {2009 {{IEEE Workshop}} on {{Advanced Robotics}} and Its {{Social Impacts}}},
  author = {Fukui, Hidetoshi and Yonejima, Satoshi and Yamano, Masatake and Dohi, Masao and Yamada, Mariko and Nishiki, Tomonori},
  year = {2009},
  month = nov,
  pages = {72--77},
  issn = {2162-7576},
  doi = {10.1109/ARSO.2009.5587070},
  urldate = {2024-03-26},
  abstract = {In factory automation (FA) industry, it is essential for the working environment using industrial robots to be provided with measures that assure operator's safety and good usability of machines. We have studied the operator's safety and usability of portable robotic operation terminals, and have developed the standardized terminals for one-hand operation suitable to many types of applications. The findings and knowledge we obtained through the development materialized recently as the new two-hand portable robotic operation terminal which is designed ergonomically. In this paper, we report on the new operation terminal which provides excellent operational safety and usability, and also a study on the effectiveness of wireless terminals for improving the usability of entire system.},
  keywords = {Education,Robot kinematics,Safety,Service robots,Usability,Wireless communication},
  file = {/home/test/Zotero/storage/L5J8XV9K/5587070.html}
}

@inproceedings{goel2019,
  title = {Leader {{And Predator Based Swarm Steering For Multiple Tasks}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Systems}}, {{Man}} and {{Cybernetics}} ({{SMC}})},
  author = {Goel, Raghavv and Lewis, John and Goodrich, M.A. and Sujit, P.B.},
  year = {2019},
  month = oct,
  pages = {3791--3798},
  issn = {2577-1655},
  doi = {10.1109/SMC.2019.8913942},
  urldate = {2024-01-09},
  abstract = {A robotic swarm can perform various tasks. However, a human is required to task the swarm. Human control over the swarm can be enabled through a set of influential agents which can be either leaders or predators. In the presence of multiple tasks, the swarm may need to split into sub-swarms to accomplish the task and re-group as a swarm to execute larger tasks. The response of the swarm in the presence of influential agents depends on the swarm dynamics. A precise measure of influence using leaders or predators or a combination of leaders and predators to achieve the mission is not adequately studied. In this paper, we analyze the effect of using only leaders, only predators and a combination of leaders and predators on three swarm models namely, shepherding model, Couzin's model and a physicomimetic models while they perform foraging tasks and carry out Monte-Carlo simulations to evaluate the performance of the influential agents on different swarms. We also propose a novel way to split a swarm into smaller sub-swarms using influential agents. Our results show that the predator based swarm splitting and steering to a task based on shepherding model performs far better than any other combination of leaders and predators. This result is consistent even when the number of agents is increased to 500.},
  file = {/home/test/Zotero/storage/E7JIMXWF/8913942.html}
}

@inproceedings{gunasundari2023,
  title = {Gesture {{Controlled Drone Swarm System}} for {{Violence Detection Using Machine Learning}} for {{Women Safety}}},
  booktitle = {Intelligent {{Sustainable Systems}}},
  author = {Gunasundari, S. and Rakhul, K. R. and Shankar, V. Ananth Sai and Sathiyan, A. R. and Balasubramanian, Ragavendiran and Krishnan, Yedhu},
  editor = {Raj, Jennifer S. and Perikos, Isidoros and Balas, Valentina Emilia},
  year = {2023},
  series = {Lecture {{Notes}} in {{Networks}} and {{Systems}}},
  pages = {221--236},
  publisher = {Springer Nature},
  address = {Singapore},
  doi = {10.1007/978-981-99-1726-6_17},
  abstract = {The safety of women is an important issue. Major constraints in handling of these cases are that the police are not aware of the location of crime during the time and the crime itself. Victims find it difficult to inform the police. To aid police, this paper proposes the design and development of Gesture Controlled Drone which uses Machine Learning algorithms to track the user and to detect signs of aggression directed towards the user. In such cases an event is detected or suspicious to happen, the complimentary Android App shall alert a selected set of contacts of the user's woes and where-abouts, while also informing the local police station. The proposed gesture-controlled drone is implemented and performance of the system is analyzed. Experimental results reveal that the proposed system works better and it is effective.},
  isbn = {978-981-9917-26-6},
  langid = {english},
  keywords = {Autonomous unmanned aerial vehicle,Gesture-controlled drone,Machine learning,swarm control,Women safety}
}

@article{hayes,
  title = {Hydrocarbon {{Lakes}} on {{Titan}} and {{Their Role}} in the {{Methane Cycle}}},
  author = {Hayes, Alexander G},
  langid = {english},
  file = {/home/test/Zotero/storage/477YD693/Hayes - Hydrocarbon Lakes on Titan and Their Role in the M.pdf}
}

@inproceedings{holstius2004,
  title = {Infotropism: Living and Robotic Plants as Interactive Displays},
  shorttitle = {Infotropism},
  booktitle = {Proceedings of the 5th Conference on {{Designing}} Interactive Systems: Processes, Practices, Methods, and Techniques},
  author = {Holstius, David and Kembel, John and Hurst, Amy and Wan, Peng-Hui and Forlizzi, Jodi},
  year = {2004},
  month = aug,
  series = {{{DIS}} '04},
  pages = {215--221},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1013115.1013145},
  urldate = {2024-01-07},
  abstract = {Designers often borrow from the natural world to achieve pleasing, unobtrusive designs. We have extended this practice by combining living plants with sensors and lights in an interactive display, and by creating a robotic analogue that mimics phototropic behavior. In this paper, we document our design process and report the results of a 2-week field study. We put our living plant display, and its robotic counterpart, in a cafeteria between pairs of trash and recycling containers. Contributions of recyclables or trash triggered directional bursts of light that gradually induced the plant displays to lean toward the more active container. In interviews, people offered explanations for the displays and spoke of caring for the plants. A marginally significant increase in recycling behavior (p=.08) occurred at the display with living plants. Apparent increases also occurred at the robotic display and a unit with only lights. Our findings indicate value in exploring the use of living material and biomimetic forms in displays, and in using lightweight robotics to deliver simple rewards.},
  isbn = {978-1-58113-787-3},
  keywords = {ambient displays,biomimetics,interactive displays,plants,recycling,robots}
}

@misc{https://www.jpl.nasa.gov,
  title = {{{CADRE}}},
  author = {{https://www.jpl.nasa.gov}},
  journal = {NASA Jet Propulsion Laboratory (JPL)},
  urldate = {2024-03-26},
  abstract = {A trio of small rovers will work as a team to explore the Moon autonomously, mapping the subsurface in 3D, collecting distributed measurements, and showing the potential of multirobot missions.},
  howpublished = {https://www.jpl.nasa.gov/missions/cadre},
  langid = {american},
  file = {/home/test/Zotero/storage/IU66K6NP/cadre.html}
}

@misc{InstallationZoteroDocumentation,
  title = {Installation [{{Zotero Documentation}}]},
  urldate = {2023-12-31},
  howpublished = {https://www.zotero.org/support/installation},
  file = {/home/test/Zotero/storage/5Z8YKZE5/installation.html}
}

@article{kolling2013,
  title = {Human {{Swarm Interaction}}: {{An Experimental Study}} of {{Two Types}} of {{Interaction}} with {{Foraging Swarms}}},
  shorttitle = {Human {{Swarm Interaction}}},
  author = {Kolling, Andreas and Sycara, Katia and Nunnally, Steve and Lewis, Michael},
  year = {2013},
  month = jun,
  journal = {Journal of Human-Robot Interaction},
  volume = {2},
  number = {2},
  pages = {103--128},
  issn = {2163-0364},
  doi = {10.5898/JHRI.2.2.Kolling},
  urldate = {2024-01-09},
  langid = {english},
  file = {/home/test/Zotero/storage/DMYVT5BQ/Kolling et al. - 2013 - Human Swarm Interaction An Experimental Study of .pdf}
}

@article{kruger2023,
  title = {Starling {{Formation-Flying Optical Experiment}} ({{StarFOX}}): {{System Design}} and {{Preflight Verification}}},
  shorttitle = {Starling {{Formation-Flying Optical Experiment}} ({{StarFOX}})},
  author = {Kruger, Justin and Koenig, Adam W. and D'Amico, Simone},
  year = {2023},
  journal = {Journal of Spacecraft and Rockets},
  volume = {60},
  number = {6},
  pages = {1755--1777},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  issn = {0022-4650},
  doi = {10.2514/1.A35598},
  urldate = {2024-03-26},
  abstract = {The Starling Formation-Flying Optical Experiment (StarFOX) is intended as the first on-orbit demonstration of autonomous distributed angles-only navigation for spacecraft swarms. StarFOX applies the angles-only Absolute and Relative Trajectory System (ARTMS), a navigation architecture consisting of three innovative algorithms: image processing, which identifies and tracks multiple targets in images from a single camera without a priori relative orbit knowledge; batch orbit determination, which autonomously initializes orbit estimates for visible swarm members; and sequential orbit determination, which continuously refines the swarm state by fusing measurements from multiple observers exchanged over an intersatellite link. Nonlinear dynamics and measurement models provide sufficient observability to estimate absolute orbits, relative orbits, and auxiliary states using only bearing angles without maneuvers. StarFOX will be conducted using a four-CubeSat swarm as part of the NASA Starling mission, and simulations of experiment scenarios demonstrate that ARTMS meets mission performance requirements. Results indicate that mean bearing angle errors are below 35{$\prime\prime$} (1{$\sigma$}), initial target range errors are below 20\% of true separation, and steady-state range errors are below 2\% (1{$\sigma$}). Absolute orbit estimation accuracy is on the order of 100 m. Hardware-in-the-loop tests display robust navigation under a variety of conditions, enabling autonomous, ubiquitous navigation with minimal ground interaction for future distributed missions.},
  file = {/home/test/Zotero/storage/AZ6QGZPA/1.html}
}

@inproceedings{kuribayashi2007,
  title = {I/{{O}} Plant: A Tool Kit for Designing Augmented Human-Plant Interactions},
  shorttitle = {I/{{O}} Plant},
  booktitle = {{{CHI}} '07 {{Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kuribayashi, Satoshi and Sakamoto, Yusuke and Tanaka, Hiroya},
  year = {2007},
  month = apr,
  series = {{{CHI EA}} '07},
  pages = {2537--2542},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1240866.1241037},
  urldate = {2024-01-07},
  abstract = {In this paper, we introduce the versatile creative tool called "I/O Plant" which generates new-style interactions among humans, plants and computers. It enables designers to manipulate plants as modules by attaching actuators and sensors to plants. It has been designed to create original hybrid circuits. We report not only our tool, but also use patterns and several examples. I/O Plant cultivates new creativity toward the interaction design.},
  isbn = {978-1-59593-642-4},
  keywords = {ambient interface,biological signal,interaction,plants}
}

@article{leeWearableDroneController2023,
  title = {Wearable {{Drone Controller}}: {{Machine Learning-Based Hand Gesture Recognition}} and {{Vibrotactile Feedback}}},
  shorttitle = {Wearable {{Drone Controller}}},
  author = {Lee, Ji-Won and Yu, Kee-Ho},
  year = {2023},
  month = jan,
  journal = {Sensors},
  volume = {23},
  number = {5},
  pages = {2666},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s23052666},
  urldate = {2024-01-04},
  abstract = {We proposed a wearable drone controller with hand gesture recognition and vibrotactile feedback. The intended hand motions of the user are sensed by an inertial measurement unit (IMU) placed on the back of the hand, and the signals are analyzed and classified using machine learning models. The recognized hand gestures control the drone, and the obstacle information in the heading direction of the drone is fed back to the user by activating the vibration motor attached to the wrist. Simulation experiments for drone operation were performed, and the participants' subjective evaluations regarding the controller's convenience and effectiveness were investigated. Finally, experiments with a real drone were conducted and discussed to validate the proposed controller.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {hand gesture recognition,human-drone interface,machine learning,vibrotactile feedback,wearable device},
  file = {/home/test/Zotero/storage/T4GYV9M4/Lee and Yu - 2023 - Wearable Drone Controller Machine Learning-Based .pdf}
}

@article{lew2020,
  title = {Plant {{Nanobionic Sensors}} for {{Arsenic Detection}}},
  author = {Lew, Tedrick Thomas Salim and Park, Minkyung and Cui, Jianqiao and Strano, Michael S.},
  year = {2020},
  month = nov,
  journal = {Wiley},
  publisher = {Wiley},
  issn = {0935-9648},
  urldate = {2024-01-07},
  copyright = {Creative Commons Attribution-Noncommercial-Share Alike},
  langid = {english},
  annotation = {Accepted: 2022-02-18T15:06:14Z},
  file = {/home/test/Zotero/storage/DSEW7R2U/Lew et al. - 2020 - Plant Nanobionic Sensors for Arsenic Detection.pdf}
}

@article{li2022,
  title = {Robotic {{Herding}} of {{Farm Animals Using}} a {{Network}} of {{Barking Aerial Drones}}},
  author = {Li, Xiaohui and Huang, Hailong and Savkin, Andrey V. and Zhang, Jian},
  year = {2022},
  month = feb,
  journal = {Drones},
  volume = {6},
  number = {2},
  pages = {29},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2504-446X},
  doi = {10.3390/drones6020029},
  urldate = {2024-01-09},
  abstract = {This paper proposes a novel robotic animal herding system based on a network of autonomous barking drones. The objective of such a system is to replace traditional herding methods (e.g., dogs) so that a large number (e.g., thousands) of farm animals such as sheep can be quickly collected from a sparse status and then driven to a designated location (e.g., a sheepfold). In this paper, we particularly focus on the motion control of the barking drones. To this end, a computationally efficient sliding mode based control algorithm is developed, which navigates the drones to track the moving boundary of the animals' footprint and enables the drones to avoid collisions with others. Extensive computer simulations, where the dynamics of the animals follow Reynolds' rules, show the effectiveness of the proposed approach.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {autonomous drones,motion control,precision farming,robotic herding,shepherding,swarm guidance,unmanned aerial vehicles (UAVs)},
  file = {/home/test/Zotero/storage/6HIB72L5/Li et al. - 2022 - Robotic Herding of Farm Animals Using a Network of.pdf}
}

@misc{LunarMarketAssessment,
  title = {Lunar Market Assessment 2021},
  keywords = {market research},
  file = {/home/test/Zotero/storage/AG2Y7YWR/lunar-market-assessment-2021.pdf}
}

@article{marzullo2012,
  title = {The {{SpikerBox}}: {{A Low Cost}}, {{Open-Source BioAmplifier}} for {{Increasing Public Participation}} in {{Neuroscience Inquiry}}},
  shorttitle = {The {{SpikerBox}}},
  author = {Marzullo, Timothy C. and Gage, Gregory J.},
  year = {2012},
  month = mar,
  journal = {PLOS ONE},
  volume = {7},
  number = {3},
  pages = {e30837},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0030837},
  urldate = {2024-01-07},
  abstract = {Although people are generally interested in how the brain functions, neuroscience education for the public is hampered by a lack of low cost and engaging teaching materials. To address this, we developed an open-source tool, the SpikerBox, which is appropriate for use in middle/high school educational programs and by amateurs. This device can be used in easy experiments in which students insert sewing pins into the leg of a cockroach, or other invertebrate, to amplify and listen to the electrical activity of neurons. With the cockroach leg preparation, students can hear and see (using a smartphone oscilloscope app we have developed) the dramatic changes in activity caused by touching the mechanosensitive barbs. Students can also experiment with other manipulations such as temperature, drugs, and microstimulation that affect the neural activity. We include teaching guides and other resources in the supplemental materials. These hands-on lessons with the SpikerBox have proven to be effective in teaching basic neuroscience.},
  langid = {english},
  keywords = {Action potentials,Cockroaches,Electronics,Legs,Neurons,Neuroscience,Teachers,Workshops},
  file = {/home/test/Zotero/storage/RHKI6FT3/Marzullo and Gage - 2012 - The SpikerBox A Low Cost, Open-Source BioAmplifie.pdf}
}

@inproceedings{mccoggle2022,
  title = {Biosensors {{Based Controller}} for {{Small Unmanned Aerial Vehicle Navigation}}},
  booktitle = {{{SoutheastCon}} 2022},
  author = {McCoggle, Mylena and Wilson, Shyra and Rivera, Andrea and {Alba-Flores}, Rocio and Soloiu, Valentin},
  year = {2022},
  month = mar,
  pages = {380--384},
  publisher = {IEEE},
  address = {Mobile, AL, USA},
  doi = {10.1109/SoutheastCon48659.2022.9764015},
  urldate = {2024-01-04},
  abstract = {This work describes a system that uses electromyography (EMG) signals obtained from muscle sensors and an Artificial Neural Network (ANN) for signal classification and pattern recognition that is used to control a small unmanned aerial vehicle using specific arm movements. The main objective of this endeavor is the development an intelligent interface that allows the user to control the flight of a drone beyond direct manual control. The biosensors used in this work were the MyoWare Muscle sensors which contain two EMG electrodes and were used to collect signals from the posterior (extensor) and anterior (flexor) forearm, and the bicep. The collection of the raw signals from each sensor were performed using an Arduino Uno. Data processing algorithms were developed with the purpose of classifying the signals generated by the arm's muscles when performing specific movements, namely: flexing, resting, arm-up, and arm motion from right to left. With these arm motions, roll control of the drone was achieved. MATLAB software was utilized to condition the signals and prepare them for the classification stage. To generate the input vector for the ANN and perform the classification, the root mean squared, and the standard deviation were processed for the signals from each electrode. The neuromuscular information was trained using an ANN with a single 10 neurons hidden layer to categorize the four targets. The result of the classification shows that an accuracy of 97.5\% was obtained for a single user. Afterwards, classification results were used to generate the appropriate control signals from the computer to the drone through a Wi-Fi network connection. These procedures were successfully tested, where the drone responded successfully in real time to the commanded inputs.},
  isbn = {978-1-66540-652-9},
  langid = {english},
  file = {/home/test/Zotero/storage/F2PK53QV/McCoggle et al. - 2022 - Biosensors Based Controller for Small Unmanned Aer.pdf}
}

@misc{oezkaya2020,
  title = {Recognizing {{Individuals}} and {{Their Emotions Using Plants}} as {{Bio-Sensors}} through {{Electro-static Discharge}}},
  author = {Oezkaya, Buenyamin and Gloor, Peter A.},
  year = {2020},
  month = may,
  number = {arXiv:2005.04591},
  eprint = {2005.04591},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2005.04591},
  urldate = {2024-01-07},
  abstract = {By measuring the electrostatic discharge of human bodies together with Mimosa Pudica and other plants in response to the human movement, we have been able to recognize (a) individuals based on their distinctive pattern of body movements with 66\% accuracy as well as (b) positive or negative mood based on their gait characteristics with 85\% accuracy. We use the Plant SpikerBox, a device that measures the electrical action potential while also measuring the electrostatic discharge between the electrode on the leaves of a plant and the capacitively coupled human body.},
  archiveprefix = {arxiv},
  keywords = {Electrical Engineering and Systems Science - Signal Processing},
  file = {/home/test/Zotero/storage/HEET8GEY/Oezkaya and Gloor - 2020 - Recognizing Individuals and Their Emotions Using P.pdf;/home/test/Zotero/storage/29YIEHJJ/2005.html}
}

@misc{pichierri2023,
  title = {{{CrazyChoir}}: {{Flying Swarms}} of {{Crazyflie Quadrotors}} in {{ROS}} 2},
  shorttitle = {{{CrazyChoir}}},
  author = {Pichierri, Lorenzo and Testa, Andrea and Notarstefano, Giuseppe},
  year = {2023},
  month = may,
  number = {arXiv:2302.00716},
  eprint = {2302.00716},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-01-04},
  abstract = {This paper introduces CrazyChoir, a modular Python framework based on the Robot Operating System (ROS) 2. The toolbox provides a comprehensive set of functionalities to simulate and run experiments on teams of cooperating Crazyflie nano-quadrotors. Specifically, it allows users to perform realistic simulations over robotic simulators as, e.g., Webots and includes bindings of the firmware control and planning functions. The toolbox also provides libraries to perform radio communication with Crazyflie directly inside ROS 2 scripts. The package can be thus used to design, implement and test planning strategies and control schemes for a Crazyflie nano-quadrotor. Moreover, the modular structure of CrazyChoir allows users to easily implement online distributed optimization and control schemes over multiple quadrotors. The CrazyChoir package is validated via simulations and experiments on a swarm of Crazyflies for formation control, pickup-and-delivery vehicle routing and trajectory tracking tasks. CrazyChoir is available at https://github.com/OPT4SMART/crazychoir.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Robotics,swarm},
  file = {/home/test/Zotero/storage/JZ3DQPMQ/Pichierri et al. - 2023 - CrazyChoir Flying Swarms of Crazyflie Quadrotors .pdf;/home/test/Zotero/storage/UDD9M7XQ/2302.html}
}

@inproceedings{sareen2019,
  title = {Cyborg {{Botany}}: {{Augmented Plants}} as {{Sensors}}, {{Displays}} and {{Actuators}}},
  shorttitle = {Cyborg {{Botany}}},
  booktitle = {Extended {{Abstracts}} of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Sareen, Harpreet and Zheng, Jiefu and Maes, Pattie},
  year = {2019},
  month = may,
  series = {{{CHI EA}} '19},
  pages = {1--2},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3290607.3311778},
  urldate = {2024-01-07},
  abstract = {The nature has myriad plant organisms, many of them carrying unique sensing and expression abilities. Plants can sense the environment, other living entities and regenerate, actuate or grow in response. Our interaction mechanisms and communication channels with such organisms in nature are subtle, unlike our interaction with digital devices. We propose a new convergent view of interaction design in nature by merging and powering our electronic functionalities with existing biological functions of plants. Cyborg Botany is a design exploration of deep technological integration within plants. Each desired synthetic function is grown, injected or carefully placed in conjunction with a plant's natural functions. With a nanowire grown inside the xylem of a plant [1, 2, 3, 4], we demonstrate its use as a touch sensor, motion sensor, antenna and more. We also demonstrate a software through which a user clicks on a plant's leaves to individual control their movement [6], and explore the use of plants as a display [5]. Our goal is to make use of a plant's own sensing and expressive abilities of nature for our interaction devices. Merging synthetic circuitry with plant's own physiology could pave a way to make these lifeforms responsive to our interactions and their ubiquitous sustainable deployment.},
  isbn = {978-1-4503-5971-9},
  keywords = {botany,emerging interfaces,hardware,interaction design,plant electronic interfaces}
}

@article{schranz2020,
  title = {Swarm {{Robotic Behaviors}} and {{Current Applications}}},
  author = {Schranz, Melanie and Umlauft, Martina and Sende, Micha and Elmenreich, Wilfried},
  year = {2020},
  journal = {Frontiers in Robotics and AI},
  volume = {7},
  issn = {2296-9144},
  urldate = {2024-01-09},
  abstract = {In swarm robotics multiple robots collectively solve problems by forming advantageous structures and behaviors similar to the ones observed in natural systems, such as swarms of bees, birds, or fish. However, the step to industrial applications has not yet been made successfully. Literature is light on real-world swarm applications that apply actual swarm algorithms. Typically, only parts of swarm algorithms are used which we refer to as basic swarm behaviors. In this paper we collect and categorize these behaviors into spatial organization, navigation, decision making, and miscellaneous. This taxonomy is then applied to categorize a number of existing swarm robotic applications from research and industrial domains. Along with the classification, we give a comprehensive overview of research platforms that can be used for testing and evaluating swarm behavior, systems that are already on the market, and projects that target a specific market. Results from this survey show that swarm robotic applications are still rare today. Many industrial projects still rely on centralized control, and even though a solution with multiple robots is employed, the principal idea of swarm robotics of distributed decision making is neglected. We identified mainly following reasons: First of all, swarm behavior emerging from local interactions is hard to predict and a proof of its eligibility for applications in an industrial context is difficult to provide. Second, current communication architectures often do not match requirements for swarm communication, which often leads to a system with a centralized communication infrastructure. Finally, testing swarms for real industrial applications is an issue, since deployment in a productive environment is typically too risky and simulations of a target system may not be sufficiently accurate. In contrast, the research platforms present a means for transforming swarm robotics solutions from theory to prototype industrial systems.},
  file = {/home/test/Zotero/storage/IUEJRD4J/Schranz et al. - 2020 - Swarm Robotic Behaviors and Current Applications.pdf}
}

@article{siean2023,
  title = {Opportunities and {{Challenges}} in {{Human-Swarm Interaction}}: {{Systematic Review}} and {{Research Implications}}},
  shorttitle = {Opportunities and {{Challenges}} in {{Human-Swarm Interaction}}},
  author = {Siean, Alexandru-Ionut and Gradinaru, Bogdanel-Constantin and Gherman, Ovidiu-Ionut and Danubianu, Mirela and Milici, Laurentiu-Dan},
  year = {2023},
  journal = {IJACSA},
  volume = {14},
  number = {4},
  issn = {21565570, 2158107X},
  doi = {10.14569/IJACSA.2023.0140499},
  urldate = {2024-01-09},
  abstract = {We conducted a Systematic Literature Review on scientific papers that examined the interaction between operators and drone swarms based on the use of a command and control center. We present the results of a meta-analysis of nine scientific papers published in the ACM DL and IEEE Xplore databases. Our findings show that research on human-drone swarm interaction shows a disproportionate interest in hand gestures compared to other input modalities for drone swarm control. Furthermore, all articles reviewed exclusively explored gestures and the size of the swarm used in the studies was limited, with a median of 3.0 and an average of 3.8 drones per study. We compiled an inventory of interaction modalities, recognition techniques, and application types from the scientific literature, which is presented in this paper. On the basis of our findings, we propose four areas for future research that can guide scientific investigations and practical developments in this field.},
  langid = {english},
  file = {/home/test/Zotero/storage/LUZCEKV3/Siean et al. - 2023 - Opportunities and Challenges in Human-Swarm Intera.pdf}
}

@incollection{singhDroneHardwareDevelopment2019,
  title = {Drone {{Hardware Development}}},
  booktitle = {Industrial {{System Engineering}} for {{Drones}}: {{A Guide}} with {{Best Practices}} for {{Designing}}},
  author = {Singh, Neeraj Kumar and Muthukrishnan, Porselvan and Sanpini, Satyanarayana},
  editor = {Singh, Neeraj Kumar and Muthukrishnan, Porselvan and Sanpini, Satyanarayana},
  year = {2019},
  pages = {111--138},
  publisher = {Apress},
  address = {Berkeley, CA},
  doi = {10.1007/978-1-4842-3534-8_4},
  urldate = {2024-01-05},
  abstract = {In the previous chapter, you explored the key considerations for few of the essential ingredients of a drone. This chapter will explain how the electrical ingredients are put together to develop the hardware for the drone. At a high level, drone development can split into drone hardware development and drone system development. Drone hardware or PCBA development is a critical part of system development. The design or selection of components other than hardware completes the system design.},
  isbn = {978-1-4842-3534-8},
  langid = {english}
}

@article{song2023,
  title = {Review of {{sEMG}} for {{Robot Control}}: {{Techniques}} and {{Applications}}},
  shorttitle = {Review of {{sEMG}} for {{Robot Control}}},
  author = {Song, Tao and Yan, Zhe and Guo, Shuai and Li, Yuwen and Li, Xianhua and Xi, Fengfeng},
  year = {2023},
  month = jan,
  journal = {Applied Sciences},
  volume = {13},
  number = {17},
  pages = {9546},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app13179546},
  urldate = {2024-01-09},
  abstract = {Surface electromyography (sEMG) is a promising technology that can capture muscle activation signals to control robots through novel human--machine interfaces (HMIs). This technology has already been applied in scenarios such as prosthetic design, assisted robot control, and rehabilitation training. This article provides an overview of sEMG-based robot control, covering two important aspects: (1) sEMG signal processing and classification methods and (2) robot control strategies and methods based on sEMG. First, the article outlines the general steps in sEMG signal processing and summarizes the commonly used methods for data acquisition, pre-processing, and feature extraction. In addition, machine-learning-based pattern recognition methods have been introduced for sEMG signal classification. Subsequently, user intent-based robot control strategies are classified into three categories: full-human continuous control, semi-autonomous continuous control, and discrete control, and their control methods and applicable scenarios are compared. Finally, this article discusses the advantages, disadvantages, and future development prospects of sEMG-based robot control. This review provides a comprehensive overview of sEMG-based robot control, from signal processing and classification methods to robot control strategies and methods, aiming to guide future research on selecting filters, feature sets, and pattern recognition methods and to assist in establishing sEMG-driven robot control frameworks.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {pattern recognition,rehabilitation,robot control,sEMG,signal processing},
  file = {/home/test/Zotero/storage/55LND2H5/Song et al. - 2023 - Review of sEMG for Robot Control Techniques and A.pdf}
}

@article{st-onge2020,
  title = {From {{Design}} to {{Deployment}}: {{Decentralized Coordination}} of {{Heterogeneous Robotic Teams}}},
  shorttitle = {From {{Design}} to {{Deployment}}},
  author = {{St-Onge}, David and Varadharajan, Vivek and Svogor, Ivan and Beltrame, Giovanni},
  year = {2020},
  month = may,
  journal = {Frontiers in Robotics and AI},
  volume = {7},
  pages = {51},
  doi = {10.3389/frobt.2020.00051},
  abstract = {Many applications benefit from the use of multiple robots, but their scalability and applicability are fundamentally limited when relying on a central control station. Getting beyond the centralized approach can increase the complexity of the embedded software, the sensitivity to the network topology, and render the deployment on physical devices tedious and error-prone. This work introduces a software-based solution to cope with these challenges on commercial hardware. We bring together our previous work on Buzz, the swarm-oriented programming language, and the many contributions of the Robotic Operating System (ROS) community into a reliable workflow, from rapid prototyping of decentralized behaviors up to robust field deployment. The Buzz programming language is a hardware independent, domain-specific (swarm-oriented), and composable language. From simulation to the field, a Buzz script can stay unmodified and almost seamlessly applicable to all units of a heterogeneous robotic team. We present the software structure of our solution, and the swarm-oriented paradigms it encompasses. While the design of a new behavior can be achieved on a lightweight simulator, we show how our security mechanisms enhance field deployment robustness. In addition, developers can update their scripts in the field using a safe software release mechanism. Integrating Buzz in ROS, adding safety mechanisms and granting field updates are core contributions essential to swarm robotics deployment: from simulation to the field. We show the applicability of our work with the implementation of two practical decentralized scenarios: a robust generic task allocation strategy and an optimized area coverage algorithm. Both behaviors are explained and tested with simulations, then experimented with heterogeneous ground-and-air robotic teams.},
  file = {/home/test/Zotero/storage/QCD2M2JJ/St-Onge et al. - 2020 - From Design to Deployment Decentralized Coordinat.pdf}
}

@article{stolfi2021,
  title = {{{UAV-UGV-UMV Multi-Swarms}} for {{Cooperative Surveillance}}},
  author = {Stolfi, Daniel H. and Brust, Matthias R. and Danoy, Gr{\'e}goire and Bouvry, Pascal},
  year = {2021},
  journal = {Frontiers in Robotics and AI},
  volume = {8},
  issn = {2296-9144},
  urldate = {2024-01-09},
  abstract = {In this paper we present a surveillance system for early detection of escapers from a restricted area based on a new swarming mobility model called CROMM-MS (Chaotic R{\"o}ssler Mobility Model for Multi-Swarms). CROMM-MS is designed for controlling the trajectories of heterogeneous multi-swarms of aerial, ground and marine unmanned vehicles with important features such as prioritising early detections and success rate. A new Competitive Coevolutionary Genetic Algorithm (CompCGA) is proposed to optimise the vehicles' parameters and escapers' evasion ability using a predator-prey approach. Our results show that CROMM-MS is not only viable for surveillance tasks but also that its results are competitive in regard to the state-of-the-art approaches.},
  file = {/home/test/Zotero/storage/CHHVHHJM/Stolfi et al. - 2021 - UAV-UGV-UMV Multi-Swarms for Cooperative Surveilla.pdf}
}

@article{sulaimanEnceladusTitanEmerging2022,
  title = {Enceladus and {{Titan}}: Emerging Worlds of the {{Solar System}}},
  shorttitle = {Enceladus and {{Titan}}},
  author = {Sulaiman, Ali H. and Achilleos, Nicholas and Bertucci, Cesar and Coates, Andrew and Dougherty, Michele and Hadid, Lina and Holmberg, Mika and Hsu, Hsiang-Wen and Kimura, Tomoki and Kurth, William and Gall, Alice Le and McKevitt, James and Morooka, Michiko and Murakami, Go and Regoli, Leonardo and Roussos, Elias and Saur, Joachim and Shebanits, Oleg and Solomonidou, Anezina and Wahlund, Jan-Erik and Waite, J. Hunter},
  year = {2022},
  month = dec,
  journal = {Exp Astron},
  volume = {54},
  number = {2},
  pages = {849--876},
  issn = {1572-9508},
  doi = {10.1007/s10686-021-09810-z},
  urldate = {2024-01-04},
  abstract = {Some of the major discoveries of the recent Cassini-Huygens mission have put Titan and Enceladus firmly on the Solar System map. The mission has revolutionised our view of Solar System satellites, arguably matching their scientific importance with that of their host planet. While Cassini-Huygens has made big surprises in revealing Titan's organically rich environment and Enceladus' cryovolcanism, the mission's success naturally leads us to further probe these findings. We advocate the acknowledgement of Titan and Enceladus science as highly relevant to ESA's long-term roadmap, as logical follow-on to Cassini-Huygens. In this White Paper, we will outline important science questions regarding these satellites and identify the science themes we recommend ESA cover during the Voyage 2050 planning cycle. Addressing these science themes would make major advancements to the present knowledge we have about the Solar System, its formation, evolution, and likelihood that other habitable environments exist outside the Earth's biosphere.},
  langid = {english},
  keywords = {Enceladus,Titan,Voyage 2050},
  file = {/home/test/Zotero/storage/2QUZHRSF/Sulaiman et al. - 2022 - Enceladus and Titan emerging worlds of the Solar .pdf}
}

@misc{technologies,
  title = {Filter {{Topology Face Off}}: {{A}} Closer Look at the Top 4 Filter Types},
  author = {Technologies, Biley},
  journal = {Filter Topology Face Off: A closer look at the top 4 filter types},
  urldate = {2024-02-22}
}

@misc{tripathi2022,
  title = {{{WiSwarm}}: {{Age-of-Information-based Wireless Networking}} for {{Collaborative Teams}} of {{UAVs}}},
  shorttitle = {{{WiSwarm}}},
  author = {Tripathi, Vishrant and Kadota, Igor and Tal, Ezra and Rahman, Muhammad Shahir and Warren, Alexander and Karaman, Sertac and Modiano, Eytan},
  year = {2022},
  month = dec,
  number = {arXiv:2212.03298},
  eprint = {2212.03298},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2212.03298},
  urldate = {2024-01-13},
  abstract = {The Age-of-Information (AoI) metric has been widely studied in the theoretical communication networks and queuing systems literature. However, experimental evaluation of its applicability to complex real-world time-sensitive systems is largely lacking. In this work, we develop, implement, and evaluate an AoI-based application layer middleware that enables the customization of WiFi networks to the needs of time-sensitive applications. By controlling the storage and flow of information in the underlying WiFi network, our middleware can: (i) prevent packet collisions; (ii) discard stale packets that are no longer useful; and (iii) dynamically prioritize the transmission of the most relevant information. To demonstrate the benefits of our middleware, we implement a mobility tracking application using a swarm of UAVs communicating with a central controller via WiFi. Our experimental results show that, when compared to WiFi-UDP/WiFi-TCP, the middleware can improve information freshness by a factor of 109x/48x and tracking accuracy by a factor of 4x/6x, respectively. Most importantly, our results also show that the performance gains of our approach increase as the system scales and/or the traffic load increases.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Networking and Internet Architecture,Computer Science - Robotics},
  file = {/home/test/Zotero/storage/8KRNTKNI/Tripathi et al. - 2022 - WiSwarm Age-of-Information-based Wireless Network.pdf;/home/test/Zotero/storage/EJE89S4W/2212.html}
}

@misc{upsidedownlabs,
  title = {{{BioAmp EMG}}},
  author = {{upsidedown labs}}
}

@misc{USUAeroLab,
  title = {{{USU AeroLab}}},
  urldate = {2024-01-05},
  howpublished = {https://aerolab.usu.edu/home},
  file = {/home/test/Zotero/storage/SEA4M3LZ/home.html}
}

@misc{vega2023,
  title = {Simulate {{Less}}, {{Expect More}}: {{Bringing Robot Swarms}} to {{Life}} via {{Low-Fidelity Simulations}}},
  shorttitle = {Simulate {{Less}}, {{Expect More}}},
  author = {Vega, Ricardo and Zhu, Kevin and Luke, Sean and Parsa, Maryam and Nowzari, Cameron},
  year = {2023},
  month = jan,
  number = {arXiv:2301.09018},
  eprint = {2301.09018},
  primaryclass = {cs, eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2301.09018},
  urldate = {2024-01-13},
  abstract = {This paper proposes a novel methodology for addressing the simulation-reality gap for multi-robot swarm systems. Rather than immediately try to shrink or `bridge the gap' anytime a real-world experiment failed that worked in simulation, we characterize conditions under which this is actually necessary. When these conditions are not satisfied, we show how very simple simulators can still be used to both (i) design new multi-robot systems, and (ii) guide real-world swarming experiments towards certain emergent behaviors when the gap is very large. The key ideas are an iterative simulator-in-the-design-loop in which real-world experiments, simulator modifications, and simulated experiments are intimately coupled in a way that minds the gap without needing to shrink it, as well as the use of minimally viable phase diagrams to guide real world experiments. We demonstrate the usefulness of our methods on deploying a real multi-robot swarm system to successfully exhibit an emergent milling behavior.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control},
  file = {/home/test/Zotero/storage/GK934TYJ/Vega et al. - 2023 - Simulate Less, Expect More Bringing Robot Swarms .pdf;/home/test/Zotero/storage/TFITIUK5/2301.html}
}

@article{vosniakosMechanicalDesignCustomized2022,
  title = {On the Mechanical Design of a Customized {{Unmanned Aerial Vehicle}} Transporter for {{Flexible Manufacturing Systems}}},
  author = {Vosniakos, George-Christopher and Lekai, Efthymios and Maltezos, Gerasimos},
  year = {2022},
  month = jan,
  journal = {IFAC-PapersOnLine},
  series = {10th {{IFAC Conference}} on {{Manufacturing Modelling}}, {{Management}} and {{Control MIM}} 2022},
  volume = {55},
  number = {10},
  pages = {989--994},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2022.09.485},
  urldate = {2024-01-05},
  abstract = {A quadcopter Unmanned Aerial Vehicle (UAV) is developed for transporting materials in Flexible Manufacturing Systems as a replacement to ground based materials handling means. It was configured using commercially available components and open dedicated software. The frame was detail designed as a bolted assembly of six truss-like parts made of Al 7075 T651 for weight reduction, ease of manufacture and repair / replacement in case of accidents. A special spring-loaded mechanism operated by the UAV's own weight was designed as a gripping interface to a standard load carrying pallet. A landing interface for accurate UAV positioning was also suggested exploiting inclined mating surfaces. All parts were manufactured on a cnc mill.},
  keywords = {accurate landing,custom design,docking,drone,high payload,passive gripping,truss design},
  file = {/home/test/Zotero/storage/L9622F7H/S2405896322017815.html}
}

@article{zhang2020,
  title = {{{SwarmTalk}} -- {{Towards Benchmark Software Suites}} for {{Swarm Robotics Platforms}}},
  author = {Zhang, Yihan and Zhang, Lyon and Wang, Hanlin and Bustamante, Fabi{\'a}n E and Rubenstein, Michael},
  year = {2020},
  journal = {New Zealand},
  abstract = {With nearly every new swarm robotic platform built, the designers develop its software stack, from low-level drivers to high-level algorithmic implementations. And while the different software stacks frequently share components, especially in robot-to-robot communication, these common components are also developed from scratch time and again. We present SwarmTalk, a new communication library that can be quickly ported to new and existing swarm hardware. SwarmTalk adopts a publish-subscribe communication model that satisfies the severe hardware constraints found in many swarms, and provides an easy-to-use programming interface. We port our SwarmTalk prototype to two hardware swarm platforms and two simulator-based platforms, and implement commonly-used swarm algorithms on these four platforms. We present the design and implementation of SwarmTalk, discuss some of the system challenges in implementation and cross-platform porting, and report on our initial experiences as a common communication abstraction for a community benchmarking suite.},
  langid = {english},
  file = {/home/test/Zotero/storage/FDUN6HY8/Zhang et al. - 2020 - SwarmTalk â€“ Towards Benchmark Software Suites for .pdf}
}

@misc{zotero-126,
  title = {{{GitHub}} - Retorquere/Zotero-Deb: {{Packaged}} Versions of {{Zotero}} and {{Juris-M}} for {{Debian-based}} Systems},
  urldate = {2024-01-27},
  howpublished = {https://github.com/retorquere/zotero-deb\#readme},
  file = {/home/test/Zotero/storage/GE64BRKQ/zotero-deb.html}
}

@misc{zotero-130,
  title = {Craig {{W}}. {{Reynolds}}},
  urldate = {2024-02-06},
  howpublished = {https://www.red3d.com/cwr/index.html},
  keywords = {pioneer},
  file = {/home/test/Zotero/storage/ALF4CZRN/index.html}
}

@misc{zotero-138,
  title = {Papers with {{Code}} - {{An ARGoS}} Plug-in for the {{Crazyflie}} Drone},
  urldate = {2024-02-10},
  abstract = {No code available yet.},
  howpublished = {https://cs.paperswithcode.com/paper/an-argos-plug-in-for-the-crazyflie-drone},
  langid = {english},
  file = {/home/test/Zotero/storage/P35EZAJT/an-argos-plug-in-for-the-crazyflie-drone.html}
}

@misc{zotero-145,
  title = {Starling},
  urldate = {2024-03-26},
  abstract = {The Starling mission will test whether the technologies work as expected, what their limitations are, and what developments are still needed for CubeSat swarms to be successful.},
  langid = {american},
  file = {/home/test/Zotero/storage/PB5Q7KNA/starling.html}
}

@misc{zotero-20,
  type = {Misc}
}

@misc{zotero-44,
  title = {Cyborgian {{Approach}} of {{Eco-interaction Design Based}} on {{Machine Intelligence}} and {{Embodied Experience}} {\textbar} {{SpringerLink}}},
  urldate = {2024-01-07},
  howpublished = {https://link.springer.com/chapter/10.1007/978-981-33-4400-6\_8},
  file = {/home/test/Zotero/storage/VR4NAPUH/978-981-33-4400-6_8.html}
}

@misc{zotero-53,
  title = {Plant {{SpikerBox}}},
  urldate = {2024-01-07},
  howpublished = {https://backyardbrains.com/products/PlantSpikerBox}
}

@misc{zotero-65,
  title = {Music Can Be Reconstructed from Human Auditory Cortex Activity Using Nonlinear Decoding Models {\textbar} {{PLOS Biology}}},
  urldate = {2024-01-08},
  howpublished = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002176},
  file = {/home/test/Zotero/storage/T2VSXANM/article.html}
}

@misc{zotero-82,
  title = {Multi-{{Operator Gesture Control}} of {{Robotic Swarms Using Wearable Devices}} - {{The Robotics Institute Carnegie Mellon University}}},
  urldate = {2024-01-09},
  howpublished = {https://www.ri.cmu.edu/publications/multi-operator-gesture-control-of-robotic-swarms-using-wearable-devices/},
  file = {/home/test/Zotero/storage/V4C3XRPE/multi-operator-gesture-control-of-robotic-swarms-using-wearable-devices.html}
}
